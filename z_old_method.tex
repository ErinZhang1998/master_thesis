% Background on the different methods on sketch representation learning
% Attribute object word embedding using Glove. \citep{joyce-chai-zscl}
% CLIP embeddings, pre-trained word embedding. Visually informed word embeddings. 
% If given an instruction ``I want to draw circular eyes'', the first question to address is where the eyes should be. Q1: Where should the part starts? This question must have been addressed by the DoodlerGAN paper, since its part generator must have generated the parts conditioned on previous parts. (What is the reason for avoiding GAN training?) The second step is determining how the eyes are drawn on paper. The descriptors will impact the dimension of the objects, such as \textit{small, big, wide, thin}. However, depending on the size of the objects, where you start the object might also be impacted, so where the bounding box starts and how big the bounding box is is dependent upon the language descriptors. Can we \textit{instill} the conditioning idea into existing methods for image generation / sketch generation? 